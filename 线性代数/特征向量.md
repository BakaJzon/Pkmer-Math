---
tags: 
  - 数学
dlink:
  - "[[--线性代数--]]"
aliases:
  - 本征向量
  - eigenvectors
  - 固有ベクトル
author: Cyletix
---
# Wikipedia
对于一个给定的方阵 $A$，它的特征向量（eigenvector，也译固有向量、本征向量）$v$ 经过这个线性变换之后，得到的新向量仍然与原来的 $v$ 保持在同一条直线上，但其长度或方向也许会改变。即
$$Av=\lambda v$$
其中 $\lambda$ 为标量，即特征向量的长度在该线性变换下缩放的比例，称 $\lambda$ 为其特征值（eigenvalue，也译固有值、本征值）。
- 如果特征值为正，则表示 $v$ 在经过线性变换的作用后方向也不变；
- 如果特征值为负，说明方向会反转；
- 如果特征值为0，则是表示缩回零点。
- 但无论怎样，仍在同一条直线上。



如何计算特征向量
> [!ai]+ ChatGPT
>
> 特征向量是指在矩阵运算中，一个非零向量在线性变换下只发生伸缩变化而不改变方向的向量。计算特征向量的步骤如下：
> 1. 对于一个 n×n 的矩阵 A，先计算其特征多项式：$det(A-λI) = 0$，其中 I 是单位矩阵，λ 是特征值。
> 2. 解特征多项式得到特征值 λ1，λ2，…，λn。
> 3. 将每个特征值代入方程组 $(A-λiI)v = 0$ 中，并求解该方程组。其中 v 是一个 n 维列向量。
> 4. 求解方程组得到的解即为对应于每个特征值的特征向量。
> 需要注意的是，在实际计算过程中，可能会遇到矩阵无法求逆或解出的情况。此时需要采用其他方法求解特征值和特征向量，如幂法、反幂法、QR方法等。


# 计算特征向量
对于n维矩阵A, 
## 1. $|\lambda E-A|=0$ 
根据此行列式的等式得到n个方程
## 2. 解特征值
此步善用[[行列式性质]]
一定会得到n个根$\lambda_{1},\lambda_{2},\lambda_{3},\dots$ (重根, 复根也计入), 
## 3. 将$\lambda$带回$|\lambda E-A|=0$ 
得到基础解系, 每个基础解系都是一个特征向量